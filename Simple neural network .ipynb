{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6485f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Initialize parameters\n",
    "\n",
    "## learning rate eta\n",
    "eta = 0.1\n",
    "\n",
    "## iterations\n",
    "N = 1\n",
    "\n",
    "## number of input features\n",
    "inp_nodes = 4\n",
    "\n",
    "## number of hidden layer nodes\n",
    "\n",
    "hidden_nodes = 6 \n",
    "\n",
    "## number of nodes at the output layer\n",
    "\n",
    "out_nodes = 3\n",
    "\n",
    "# initializing the weight for the hidden layer\n",
    "W1 = np.ones((inp_nodes,hidden_nodes))\n",
    "# initializing the bias for the hidden layer\n",
    "b1 = np.ones(hidden_nodes)\n",
    "# initializing the weight for the output layer\n",
    "W2 = np.ones((hidden_nodes,out_nodes))\n",
    "# initializing the weight for the output layer\n",
    "b2 = np.ones(out_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f3ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "\n",
    "# sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-1 * x))\n",
    "\n",
    "# Loss function\n",
    "def sum_of_squares(y,t):\n",
    "    return 0.5 * np.sum((y - t)**2)\n",
    "\n",
    "# feed forward function\n",
    "def feedforward(x,w1,w2,b1,b2):\n",
    "    \n",
    "    #summation hidden layer\n",
    "    z1 = np.dot(x,W1) + b1\n",
    "    #output in hidden layer \n",
    "    a1 = sigmoid(z1)\n",
    "    #summation in output layer\n",
    "    z2 = np.dot(a1,W2) + b2\n",
    "    #output in hidden layer \n",
    "    a2 = sigmoid(z2)\n",
    "    return (z1,a1,z2,a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of input values\n",
    "\n",
    "# -3\n",
    "# 2\n",
    "# 1\n",
    "# -1\n",
    "# 1\n",
    "# 0\n",
    "# 0\n",
    "\n",
    "\n",
    "\n",
    "#### OR\n",
    "\n",
    "# 1\n",
    "# 0\n",
    "# -2\n",
    "# -3\n",
    "# 0\n",
    "# 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfd6705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n",
      "2\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Input and target\n",
    "\n",
    "data = []\n",
    "for i in range(7):\n",
    "    value= input()\n",
    "    data.append(float(value))\n",
    "\n",
    "#The â€‚rst 4 values are the input to the network and the last 3 are the corresponding targets.\n",
    "x = np.array(data[0:4]).reshape(1,4)\n",
    "t = np.array(data[4:]).reshape(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fff74e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9645\n"
     ]
    }
   ],
   "source": [
    "# feed forward step before updating weights\n",
    "z1,a1,z2,a2= feedforward(x,W1,W2,b1,b2)\n",
    " \n",
    " #loss \n",
    "loss = sum_of_squares(a2,t)\n",
    " #print(round(loss,4))\n",
    "print(\"%.4f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c00b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Backpropagation step\n",
    "\n",
    "for n in range(N):\n",
    "   \n",
    "    # delta in the ouput layer\n",
    "    delta_out = (a2 - t)* a2 * (1 - a2)\n",
    "    \n",
    "    # updating weights and biases in the hidden layer\n",
    "    W2 = W2 - eta * np.dot(a1.T, delta_out) #transpose a1\n",
    "    b2 = b2 - eta * np.sum(delta_out, axis=0)\n",
    "    \n",
    "    # delta in the hidden layer\n",
    "    delta_h = np.dot(delta_out, W2.T) * a1 * (1 - a1)\n",
    "    \n",
    "    # updating weights and biases in the input layer\n",
    "    W1 = W1 - eta * np.dot(x.T, delta_h) #transpose x\n",
    "    b1 = b1 - eta*np.sum(delta_h, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c70da650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9636\n"
     ]
    }
   ],
   "source": [
    "\n",
    " # feed forward step after updating weights\n",
    "z1,a1,z2,a2= feedforward(x,W1,W2,b1,b2)\n",
    " \n",
    " #loss \n",
    "loss = sum_of_squares(a2,t)\n",
    " #print(round(loss,4))\n",
    "print(\"%.4f\" % loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
